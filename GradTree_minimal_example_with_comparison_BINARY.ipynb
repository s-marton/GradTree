{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf584ce8-8849-4a53-8ce9-2de8f9dd752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify GPU to use\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b07238-f972-45df-86ce-a11cc11d72e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5361\n",
      "Validation set size: 1341\n",
      "Test set size: 1676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smarton/anaconda3/envs/GradientBasedTreeLearning/lib/python3.11/site-packages/openml/datasets/functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import openml\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "# Load SpeedDating dataset\n",
    "dataset = openml.datasets.get_dataset(40536)\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Validation set size:\", len(X_valid))\n",
    "print(\"Test set size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a22e5c9-16a8-44ab-b8fa-19344b93dd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>...</th>\n",
       "      <th>expected_num_interested_in_me</th>\n",
       "      <th>expected_num_matches</th>\n",
       "      <th>d_expected_happy_with_sd_people</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0-4]</td>\n",
       "      <td>[10-20]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0-5]</td>\n",
       "      <td>[7-10]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>female</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Black/African American</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[5-6]</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[7-10]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Black/African American</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[7-10]</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[0-2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0-5]</td>\n",
       "      <td>[0-4]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[4-6]</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0-4]</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[0-2]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[0-5]</td>\n",
       "      <td>[5-6]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[7-10]</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0-5]</td>\n",
       "      <td>[0-4]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     has_null  wave  gender   age  age_o  d_age d_d_age  \\\n",
       "813         0     3  female  23.0   21.0      2   [2-3]   \n",
       "1677        1     5  female  20.0   18.0      2   [2-3]   \n",
       "2915        1     9  female  28.0   27.0      1   [0-1]   \n",
       "5972        1    15  female  28.0   24.0      4   [4-6]   \n",
       "5443        1    14    male  23.0   24.0      1   [0-1]   \n",
       "\n",
       "                                       race  \\\n",
       "813             European/Caucasian-American   \n",
       "1677                 Black/African American   \n",
       "2915                 Black/African American   \n",
       "5972            European/Caucasian-American   \n",
       "5443  Asian/Pacific Islander/Asian-American   \n",
       "\n",
       "                                     race_o samerace  ...  \\\n",
       "813             European/Caucasian-American        1  ...   \n",
       "1677  Asian/Pacific Islander/Asian-American        0  ...   \n",
       "2915  Asian/Pacific Islander/Asian-American        0  ...   \n",
       "5972            European/Caucasian-American        1  ...   \n",
       "5443                                  Other        0  ...   \n",
       "\n",
       "      expected_num_interested_in_me  expected_num_matches  \\\n",
       "813                            15.0                   3.0   \n",
       "1677                            NaN                   3.0   \n",
       "2915                            NaN                   0.0   \n",
       "5972                            NaN                   1.0   \n",
       "5443                            NaN                   4.0   \n",
       "\n",
       "     d_expected_happy_with_sd_people d_expected_num_interested_in_me  \\\n",
       "813                            [0-4]                         [10-20]   \n",
       "1677                           [5-6]                           [0-3]   \n",
       "2915                          [7-10]                           [0-3]   \n",
       "5972                           [0-4]                           [0-3]   \n",
       "5443                          [7-10]                           [0-3]   \n",
       "\n",
       "     d_expected_num_matches  like  guess_prob_liked  d_like  \\\n",
       "813                   [3-5]   5.0              10.0   [0-5]   \n",
       "1677                  [3-5]   7.0               7.0   [6-8]   \n",
       "2915                  [0-2]   NaN               NaN   [0-5]   \n",
       "5972                  [0-2]   3.0               5.0   [0-5]   \n",
       "5443                  [3-5]   5.0               4.0   [0-5]   \n",
       "\n",
       "      d_guess_prob_liked  met  \n",
       "813               [7-10]  0.0  \n",
       "1677              [7-10]  0.0  \n",
       "2915               [0-4]  NaN  \n",
       "5972               [5-6]  0.0  \n",
       "5443               [0-4]  0.0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c846edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = X_train.copy()\n",
    "X_valid_raw = X_valid.copy()\n",
    "X_test_raw = X_test.copy()\n",
    "\n",
    "low_cardinality_indices = []\n",
    "high_cardinality_indices = []\n",
    "\n",
    "categorical_feature_indices = []\n",
    "for column_index in range(X_train.shape[1]):\n",
    "    if categorical_indicator[column_index]:\n",
    "        categorical_feature_indices.append(column_index)\n",
    "        if len(X_train.iloc[:,column_index].unique()) < 10:\n",
    "            low_cardinality_indices.append(X_train.columns[column_index])\n",
    "        else:\n",
    "            high_cardinality_indices.append(X_train.columns[column_index])\n",
    "\n",
    "y_train = y_train.values.codes.astype(np.float64)\n",
    "y_valid = y_valid.values.codes.astype(np.float64)\n",
    "y_test = y_test.values.codes.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830c0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OrdinalEncoder(cols=X_train.columns[categorical_feature_indices])\n",
    "encoder.fit(X_train)\n",
    "X_train = encoder.transform(X_train).astype(np.float64)\n",
    "X_valid = encoder.transform(X_valid).astype(np.float64)\n",
    "X_test = encoder.transform(X_test).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf0a93c2-e9a4-4fa5-a7f6-44689dd07d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 13:44:44.021922: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-03 13:44:45.434620: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/smarton/anaconda3/envs/GradientBasedTreeLearning/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "2023-11-03 13:44:48.071252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46692 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:e1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 13:44:51.912407: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2462da30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-03 13:44:51.912452: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-11-03 13:44:51.924248: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-03 13:44:53.239144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8801\n",
      "2023-11-03 13:44:54.497878: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 9s 29ms/step - loss: 0.5802 - val_loss: 0.4797\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.4558 - val_loss: 0.4335\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4250 - val_loss: 0.4243\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.4106 - val_loss: 0.4178\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.4095 - val_loss: 0.3870\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3925 - val_loss: 0.3814\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3887 - val_loss: 0.3935\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3803 - val_loss: 0.3900\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3948 - val_loss: 0.3894\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3825 - val_loss: 0.3899\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.3822 - val_loss: 0.3857\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3845 - val_loss: 0.3902\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.3743 - val_loss: 0.4065\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3807 - val_loss: 0.4011\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3768 - val_loss: 0.3872\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.3788 - val_loss: 0.3767\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3731 - val_loss: 0.3800\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3752 - val_loss: 0.4067\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3715 - val_loss: 0.3813\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3705 - val_loss: 0.3906\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3745 - val_loss: 0.3748\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3761 - val_loss: 0.3942\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3701 - val_loss: 0.3918\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.3756 - val_loss: 0.3760\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3703 - val_loss: 0.3750\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3746 - val_loss: 0.3741\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.3671 - val_loss: 0.3765\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3686 - val_loss: 0.3818\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3689 - val_loss: 0.3899\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3617 - val_loss: 0.3820\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3716 - val_loss: 0.3875\n",
      "Epoch 32/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3713 - val_loss: 0.3727\n",
      "Epoch 33/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3703 - val_loss: 0.3913\n",
      "Epoch 34/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3691 - val_loss: 0.3958\n",
      "Epoch 35/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3669 - val_loss: 0.3913\n",
      "Epoch 36/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3726 - val_loss: 0.3689\n",
      "Epoch 37/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3718 - val_loss: 0.3961\n",
      "Epoch 38/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3774 - val_loss: 0.3811\n",
      "Epoch 39/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3724 - val_loss: 0.3835\n",
      "Epoch 40/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3651 - val_loss: 0.3985\n",
      "Epoch 41/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3605 - val_loss: 0.3848\n",
      "Epoch 42/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3699 - val_loss: 0.3904\n",
      "Epoch 43/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3665 - val_loss: 0.3976\n",
      "Epoch 44/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3746 - val_loss: 0.3723\n",
      "Epoch 45/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3707 - val_loss: 0.3743\n",
      "Epoch 46/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3722 - val_loss: 0.3949\n",
      "Epoch 47/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3695 - val_loss: 0.3924\n",
      "Epoch 48/1000\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.3652 - val_loss: 0.4022\n",
      "Epoch 49/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3618 - val_loss: 0.3790\n",
      "Epoch 50/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3612 - val_loss: 0.3837\n",
      "Epoch 51/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3655 - val_loss: 0.3773\n",
      "Epoch 52/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3687 - val_loss: 0.3854\n",
      "Epoch 53/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3722 - val_loss: 0.3962\n",
      "Epoch 54/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3680 - val_loss: 0.3898\n",
      "Epoch 55/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3695 - val_loss: 0.3795\n",
      "Epoch 56/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3678 - val_loss: 0.3841\n",
      "Epoch 57/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3693 - val_loss: 0.3975\n",
      "Epoch 58/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3665 - val_loss: 0.3841\n",
      "Epoch 59/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3716 - val_loss: 0.3741\n",
      "Epoch 60/1000\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.3719 - val_loss: 0.3920\n",
      "Epoch 61/1000\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.3664 - val_loss: 0.3811\n"
     ]
    }
   ],
   "source": [
    "from GradTree import GradTree\n",
    "\n",
    "params = {\n",
    "        'depth': 5,\n",
    "\n",
    "        'learning_rate_index': 0.01,\n",
    "        'learning_rate_values': 0.01,\n",
    "        'learning_rate_leaf': 0.01,\n",
    "\n",
    "        'optimizer': 'SWA',\n",
    "        'cosine_decay_steps': 0,\n",
    "\n",
    "        'initializer': 'RandomNormal',\n",
    "\n",
    "        'loss': 'crossentropy',\n",
    "        'focal_loss': False,\n",
    "        'temperature': 0.0,\n",
    "\n",
    "        'from_logits': True,\n",
    "        'apply_class_balancing': True,\n",
    "}\n",
    "\n",
    "args = {\n",
    "    'epochs': 1_000,\n",
    "    'early_stopping_epochs': 25,\n",
    "    'batch_size': 64,\n",
    "\n",
    "    'cat_idx': categorical_feature_indices,\n",
    "    'objective': 'binary',\n",
    "    \n",
    "    'metrics': ['F1'], # F1, Accuracy, R2\n",
    "    'random_seed': 42,\n",
    "    'verbose': 1,       \n",
    "}\n",
    "\n",
    "model_gradtree = GradTree(params=params, args=args)\n",
    "\n",
    "model_gradtree.fit(X_train=X_train,\n",
    "          y_train=y_train,\n",
    "          X_val=X_valid,\n",
    "          y_val=y_valid)\n",
    "\n",
    "preds_gradtree = model_gradtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b251df9d-67f0-4dd1-a0cc-379621e33fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_weights(y_data):\n",
    "    class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(y_data), y = y_data)\n",
    "    sample_weights = sklearn.utils.class_weight.compute_sample_weight(class_weight = 'balanced', y =y_data)\n",
    "    return sample_weights\n",
    "\n",
    "def calculate_class_weights(y_data):\n",
    "    class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(y_data), y = y_data)\n",
    "    return list(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d5f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = X_train.median(axis=0)\n",
    "X_train= X_train.fillna(median)\n",
    "X_vali = X_valid.fillna(median)\n",
    "X_test = X_test.fillna(median)\n",
    "\n",
    "encoder = ce.LeaveOneOutEncoder(cols=high_cardinality_indices)\n",
    "encoder.fit(X_train, y_train)\n",
    "X_train = encoder.transform(X_train)\n",
    "X_valid = encoder.transform(X_valid)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=low_cardinality_indices)\n",
    "encoder.fit(X_train)\n",
    "X_train = encoder.transform(X_train)\n",
    "X_valid = encoder.transform(X_valid)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "median = X_train.median(axis=0)\n",
    "X_train = X_train.fillna(median)\n",
    "X_valid = X_valid.fillna(median)\n",
    "X_test = X_test.fillna(median)\n",
    "\n",
    "quantile_noise = 1e-4\n",
    "quantile_train = np.copy(X_train.values).astype(np.float64)\n",
    "np.random.seed(42)\n",
    "stds = np.std(quantile_train, axis=0, keepdims=True)\n",
    "noise_std = quantile_noise / np.maximum(stds, quantile_noise)\n",
    "quantile_train += noise_std * np.random.randn(*quantile_train.shape)       \n",
    "\n",
    "scaler = sklearn.preprocessing.QuantileTransformer(output_distribution='normal')\n",
    "scaler.fit(quantile_train)\n",
    "\n",
    "X_train = scaler.transform(X_train.values.astype(np.float64))\n",
    "X_valid = scaler.transform(X_valid.values.astype(np.float64))\n",
    "X_test = scaler.transform(X_test.values.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "361f7d9f-7e58-4bc1-8855-153b9e972742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_cart = DecisionTreeClassifier(class_weight='balanced')\n",
    "model_cart.fit(np.concatenate([X_train, X_valid]), \n",
    "                np.concatenate([y_train, y_valid]),\n",
    "                \n",
    "             )\n",
    "\n",
    "preds_cart = model_cart.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21b9be01-ba30-4300-b3e0-f4fd43b55c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy GradTree: 0.8293556085918854\n",
      "F1 Score GradTree: 0.6154470683751632\n",
      "ROC AUC GradTree: 0.7688232328173328\n",
      "\n",
      "\n",
      "Accuracy CART: 0.7947494033412887\n",
      "F1 Score CART: 0.6236844647393471\n",
      "ROC AUC CART: 0.6190827381893071\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if args['objective'] == 'binary':\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.round(preds_gradtree[:,1]))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.round(preds_gradtree[:,1]), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_gradtree[:,1], average='macro', multi_class='ovo')\n",
    "\n",
    "    print('Accuracy GradTree:', accuracy)\n",
    "    print('F1 Score GradTree:', f1_score)\n",
    "    print('ROC AUC GradTree:', roc_auc)\n",
    "    print('\\n')\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.round(preds_cart[:,1]))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.round(preds_cart[:,1]), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_cart[:,1], average='macro', multi_class='ovo')\n",
    "\n",
    "    print('Accuracy CART:', accuracy)\n",
    "    print('F1 Score CART:', f1_score)\n",
    "    print('ROC AUC CART:', roc_auc)\n",
    "    print('\\n')\n",
    "    \n",
    "elif args['objective'] == 'classification':\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.argmax(preds_gradtree, axis=1))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.argmax(preds_gradtree, axis=1), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_gradtree, average='macro', multi_class='ovo', labels=[i for i in range(preds_gradtree.shape[1])])\n",
    "\n",
    "    print('Accuracy GradTree:', accuracy)\n",
    "    print('F1 Score GradTree:', f1_score)\n",
    "    print('ROC AUC GradTree:', roc_auc)\n",
    "    print('\\n')\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.argmax(preds_cart, axis=1))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.argmax(preds_cart, axis=1), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_cart, average='macro', multi_class='ovo', labels=[i for i in range(preds_gradtree.shape[1])])\n",
    "\n",
    "    print('Accuracy CART:', accuracy)\n",
    "    print('F1 Score CART:', f1_score)\n",
    "    print('ROC AUC CART:', roc_auc)\n",
    "    print('\\n')\n",
    "\n",
    "else:\n",
    "    mean_absolute_error = sklearn.metrics.mean_absolute_error(y_test, preds_gradtree)\n",
    "    r2_score = sklearn.metrics.r2_score(y_test, preds_gradtree)\n",
    "\n",
    "    print('MAE GradTree:', mean_absolute_error)\n",
    "    print('R2 Score GradTree:', r2_score)\n",
    "    print('\\n')\n",
    "\n",
    "    mean_absolute_error = sklearn.metrics.mean_absolute_error(y_test, preds_cart)\n",
    "    r2_score = sklearn.metrics.r2_score(y_test, preds_cart)\n",
    "\n",
    "    print('MAE CART:', mean_absolute_error)\n",
    "    print('R2 Score CART:', r2_score)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef810585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
